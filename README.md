# ğŸŒ¾ KCC Query Assistant

A fully local, multilingual AI assistant for answering agricultural queries using real Q&A pairs from government datasets (Krishi Call Center - KCC).

This project uses Retrieval-Augmented Generation (RAG) with **ChromaDB** and **Ollama** (`gemma:2b`) to run **completely offline** â€” no cloud, no API calls.

---

## ğŸš€ Features

- âœ… Local embeddings with `sentence-transformers` (`MiniLM`)
- âœ… Vector search using ChromaDB
- âœ… Local LLM response generation via Ollama (`gemma:2b`)
- âœ… Streamlit UI for easy Q&A interaction
- âœ… Graceful fallback when no context is found

---

## ğŸ› ï¸ Technologies

- Python 3.10
- [sentence-transformers](https://www.sbert.net/)
- [ChromaDB](https://www.trychroma.com/)
- [Ollama](https://ollama.com/) + `gemma:2b`
- Streamlit

---

## ğŸ“‚ Project Structure
- `app.py`  
  â†’ Streamlit web UI to enter queries and show results

- `query_rag.py`  
  â†’ Loads ChromaDB, retrieves top-k results, and calls Ollama for response

- `embed_store.py`  
  â†’ Embeds `kcc_chunks.json` into ChromaDB and saves the vector store locally

- `KCC_data_process.ipynb`  
  â†’ Jupyter notebook for cleaning and transforming raw KCC CSV data into Q&A format

- `kcc_chunks.json`  
  â†’ Final processed Q&A dataset used for vector search

- `requirements.txt`  
  â†’ List of Python packages needed to run the project

- `sample_queries.txt`  
  â†’ Contains 9 test questions, 5 without context  
    - ğŸ§ª **Note on Test Questions**  
      This file includes **3 test queries with valid KCC context** and **2 queries without matching context** to demonstrate fallback behavior.  
      ğŸ‘‰ **Refer to the demo video** for input/output examples and expected responses for all 5.


---

## â–¶ï¸ How to Run the Project

### 1. Install Python dependencies

```bash
pip install -r requirements.txt
```

### 2. Start Ollama with local LLM

- `chroma_store/` *(not pushed to GitHub)*  
  â†’ Auto-generated Chroma vector database directory (recreated by `embed_store.py`)

```bash
ollama run gemma:2b
```
>>> Send a message (/? for help)

- Press Ctrl + D to exit the interactive session and move on to the next step.


### 3. Run the Streamlit app

```bash
streamlit run app.py
```

- This will launch the app in your default browser.
If it doesn't open automatically, visit: http://localhost:8501

---

## ğŸ“½ï¸ Demo Video  
ğŸ”— [Click here to watch demo](https://drive.google.com/file/d/1hglyiJi6P-5Uyz4OPLm6l1qOybW-3vSn/view?usp=sharing)  <!-- Replace # with actual video link -->

Includes:
- âœ… Local Ollama + ChromaDB startup
- âœ… 3â€“5 working queries using KCC context
- âœ… 2â€“3 fallback examples (no context matched)
- âœ… All responses generated **100% offline**

---

## âš ï¸ Notes

- `chroma_store/` is **not included** in the GitHub repo.  
  â†’ Run `embed_store.py` to regenerate the local Chroma vector database.

- Ollama must be installed separately from [ollama.com](https://ollama.com).  
  â†’ Make sure it's running before using the assistant.

- âœ… Tested on **macOS (Intel)** with **Python 3.10**

---

## ğŸ¨ Block Diagram

          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   KCC_data_process    â”‚   â† (Jupyter Notebook)
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   kcc_chunks.json     â”‚   â† Preprocessed Q&A Data
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚   embed_store.py      â”‚   â† Embeds & stores in ChromaDB
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   ChromaDB (Local)     â”‚   â† Vector store: stores embeddings
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚    query_rag.py             â”‚   â† Takes user query, retrieves match
     â”‚  + SentenceTransformer      â”‚
     â”‚  + ChromaDB retrieval       â”‚
     â”‚  + Ollama (`gemma:2b`)      â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚       Streamlit UI          â”‚   â† app.py      
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
---

This repository is **temporarily public** to allow access for evaluation.  
The username **@vicharanalabs**, as mentioned in the form, could not be found on GitHub â€” so direct collaborator access was not possible.




